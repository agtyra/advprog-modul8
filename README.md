# Reflection

1. When we perform a unary RPC, the client sends a single message and the server replies with exactly one response. This style suits simple tasks—like fetching a user record or updating a setting—because there’s only one round-trip to manage.

2. Server-streaming RPC starts with one client request but allows the server to push back a series of messages. It’s ideal for scenarios such as downloading large datasets in chunks or subscribing to live updates, since we can avoid overwhelming memory and use flow control.

3. In bidirectional streaming RPC, client and server keep the connection open and exchange streams independently. This pattern fits interactive use cases—think chat systems, real-time gaming, or telemetry feeds—where both sides need to send and receive data continuously.

4. Securing a gRPC service in Rust begins with enabling TLS on all connections so traffic is encrypted. We then authenticate callers using mutual TLS certificates or signed tokens (JWT/OAuth2) in an interceptor layer and enforce authorization by mapping identities to roles or permissions stored in a safe backend. Rust’s ownership model helps prevent memory-safety bugs, but any unsafe blocks or C-library bindings demand careful boundary checks. Sensitive logs and stored data should also be encrypted at rest.

5. Handling bidirectional streams introduces extra complexity: we must preserve or tag message order, apply backpressure with bounded channels to prevent buffer overflow, detect client disconnects or idle timeouts to clean up resources, and decide whether individual errors should close the whole stream or be handled gracefully. Adding a hub to fan out messages to multiple clients brings further state-management and synchronization challenges.

6. Wrapping a Tokio `mpsc::Receiver` in `tokio_stream::wrappers::ReceiverStream` lets us expose channel messages as a gRPC response stream with minimal glue. Bounded channels provide backpressure out of the box, and we can use stream combinators to map or filter items. The trade-offs include slight per-message overhead compared to low-level handlers, one producer per channel unless we merge multiple sources manually, and the need to embed status information in our message type if we want to distinguish a normal close from an error.

7. To keep our Rust gRPC code modular, we separate generated protobuf files into a `proto` module, server implementations into `service`, and client helpers into `client`. We define key behaviors as traits—such as a `PaymentProcessor`—then provide real and mock implementations behind those traits. Cross-cutting concerns like authentication checks, logging, and metrics run in interceptor layers or Tower middleware so our service logic remains focused. Shared types, error mappers, and proto-to-domain converters live in a small `common` crate that both client and server import. This layout makes each part easy to replace, test, and extend.

8. Turning a basic `MyPaymentService` into a production-ready pipeline involves adding input validation for card data, amounts, and supported currencies; generating idempotency keys to avoid duplicate charges on retries; and wrapping multi-step flows (reserve funds, capture, settle) in transaction-safe logic or a saga pattern. We integrate with external gateways via webhooks, implement retry loops with exponential backoff and circuit breakers, and record every state change in an audit log for compliance and troubleshooting.

9. Adopting gRPC shapes our system architecture around strong, code-generated contracts defined in protobuf. HTTP/2 underlies gRPC, giving us multiplexed, compressed streams and lower latency. We typically front services with an HTTP/2-aware proxy (such as Envoy) and follow protobuf’s versioning rules to add or deprecate fields safely so old clients continue to work. The result is a highly interoperable, polyglot microservice ecosystem where Rust, Go, Java, Python, and other runtimes speak the same protocol.

10. Protocol Buffers enforce a strict, typed schema with numbered tags for compact binary encoding and compile-time validation. JSON in REST is free-form text that’s easy to inspect and tweak but larger and slower to parse, with potential runtime mismatches unless extra validation is added. In production we favor protobuf for performance and reliability, while JSON remains handy for quick debugging and external integrations.
